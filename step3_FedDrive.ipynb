{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srrmtt/AML/blob/main/step3_FedDrive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxI0OKJ9fMt7",
        "outputId": "471d6629-9d00-41ea-b543-2bb77a969924"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "!cp '/content/drive/MyDrive/client.py' './client.py'\n",
        "!cp '/content/drive/MyDrive/server.py' './server.py'\n",
        "!cp '/content/drive/MyDrive/dataset.py' './dataset.py'\n",
        "!cp '/content/drive/MyDrive/bisenetv2.py' './bisenetv2.py'\n",
        "!cp '/content/drive/MyDrive/transform.py' './transform.py'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SX5PG63TgYhP"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "from sklearn.metrics import confusion_matrix  \n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import VisionDataset\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "import os\n",
        "import os.path\n",
        "import sys\n",
        "from torch.backends import cudnn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from dataset import Cityscapes\n",
        "from client import *\n",
        "from server import *\n",
        "from bisenetv2 import *\n",
        "from transform import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "n1S_Ve97ZGTp"
      },
      "outputs": [],
      "source": [
        "#DEVICE = 'cuda' # 'cuda' or 'cpu'\n",
        "DEVICE = 'cuda'\n",
        "NUM_CLASSES = 19 # 101 + 1: There is am extra Background class that should be removed \n",
        "\n",
        "BATCH_SIZE = 16     # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\n",
        "                     # the batch size, learning rate should change by the same factor to have comparable results\n",
        "\n",
        "LR = 5*1e-3           # The initial Learning Rate\n",
        "MOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
        "WEIGHT_DECAY = 5e-5  # Regularization, you can keep this at the default -5\n",
        "\n",
        "NUM_EPOCHS = 25      # 20/30 Total number of training epochs (iterations over dataset)\n",
        "STEP_SIZE = 20       #20 How many epochs before decreasing learning rate (if using a step-down policy)\n",
        "GAMMA = 0.1          # Multiplicative factor for learning rate step-down\n",
        "\n",
        "LOG_FREQUENCY = 10"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#transformations\n",
        "size = (256, 512) #512,1024\n",
        "scales=(0.25, 2.)\n",
        "cropsize=(512, 1024)\n",
        "eval_crop=(1024, 1024)\n",
        "eval_scales=(0.5, 0.75, 1.0, 1.25, 1.5, 1.75)\n",
        "test_transformations = [RandomResizedCrop(eval_scales, eval_crop)]\n",
        "train_transformations = [RandomResizedCrop(scales,cropsize),RandomHorizontalFlip(),ColorJitter(brightness=0.4,contrast=0.4,saturation=0.4)]\n",
        "test_transformations = Compose(test_transformations)\n",
        "train_transformations = Compose(train_transformations)"
      ],
      "metadata": {
        "id": "WWS3y3_5poPS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9f83Hhq4LAH",
        "outputId": "428e3035-d245-4a85-9a3f-bbeec8b88a6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished Client ID:[0]: len: 20\n",
            "finished Client ID:[1]: len: 20\n",
            "finished Client ID:[2]: len: 20\n",
            "finished Client ID:[3]: len: 20\n",
            "finished Client ID:[4]: len: 20\n",
            "finished Client ID:[5]: len: 20\n",
            "finished Client ID:[6]: len: 20\n",
            "finished Client ID:[7]: len: 20\n",
            "finished Client ID:[8]: len: 20\n",
            "finished Client ID:[9]: len: 20\n",
            "finished Client ID:[10]: len: 20\n",
            "finished Client ID:[11]: len: 20\n",
            "finished Client ID:[12]: len: 20\n",
            "finished Client ID:[13]: len: 20\n",
            "finished Client ID:[14]: len: 20\n",
            "finished Client ID:[15]: len: 20\n",
            "finished Client ID:[16]: len: 20\n",
            "finished Client ID:[17]: len: 20\n",
            "finished Client ID:[18]: len: 20\n",
            "finished Client ID:[19]: len: 20\n",
            "finished Client ID:[20]: len: 20\n",
            "finished Client ID:[21]: len: 20\n",
            "finished Client ID:[22]: len: 20\n",
            "finished Client ID:[23]: len: 20\n",
            "finished Client ID:[24]: len: 20\n",
            "finished Client ID:[25]: len: 20\n",
            "finished Client ID:[26]: len: 20\n",
            "finished Client ID:[27]: len: 20\n",
            "finished Client ID:[28]: len: 20\n",
            "finished Client ID:[29]: len: 20\n",
            "finished Client ID:[30]: len: 20\n",
            "finished Client ID:[31]: len: 20\n",
            "finished Client ID:[32]: len: 20\n",
            "finished Client ID:[33]: len: 20\n",
            "finished Client ID:[34]: len: 20\n",
            "36 last: 35\n"
          ]
        }
      ],
      "source": [
        "\n",
        "clients = []\n",
        "datasets = []\n",
        "with open(\"/content/drive/MyDrive/data/data/Cityscapes/train_A_I.txt\") as lines:\n",
        "  curr_id = 0\n",
        "  paths = []\n",
        "  for line in lines:\n",
        "    id_client,path = line.split(\" \")\n",
        "    if curr_id == int(id_client):\n",
        "      paths.append(path)\n",
        "    else:\n",
        "      print(f\"finished Client ID:[{curr_id}]: len: {len(paths)}\")\n",
        "      dataset = DatasetClient(\"/content/drive/MyDrive/data/data/Cityscapes\",paths,train_transformations)\n",
        "      datasets.append(dataset)\n",
        "      client = Client(curr_id,dataset)\n",
        "      clients.append(client)\n",
        "\n",
        "      paths = []\n",
        "      paths.append(path)\n",
        "      curr_id = int(id_client)  \n",
        "\n",
        "  dataset = DatasetClient(\"/content/drive/MyDrive/data/data/Cityscapes\",paths,train_transformations)\n",
        "  datasets.append(dataset)\n",
        "  client = Client(curr_id,dataset)\n",
        "  clients.append(client)\n",
        "\n",
        "print(len(clients), f\"last: {curr_id}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9UNy0go3ptsL"
      },
      "outputs": [],
      "source": [
        "#test_dataloader_B = DataLoader(test_dataset_B, batch_size=1, shuffle=False, num_workers=2)\n",
        "#test_dataloader_A = DataLoader(test_dataset_A, batch_size=1, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"/content/drive/MyDrive/Results/Step2/LR5e-4_25epochs_16batchsize/dataset_A_test_mIoU/bisenet_best_mIoU_0.0005_tranformation (1).pt\"\n",
        "server = Server(clients, model_path)\n",
        "\n",
        "server.train()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "tWR60IDliIL7",
        "outputId": "087a20af-e26f-415e-8929-db601e56168a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Server]: round 0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-03ad3a8e29d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mserver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mServer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/server.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m               \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[Server]: round {i}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0;31m#back prop ?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1263\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1264\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1265\u001b[0;31m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[1;32m   1266\u001b[0m             type(self).__name__, name))\n\u001b[1;32m   1267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'BiSeNetV2' object has no attribute 'weights'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GI0zmgXzZ-e8"
      },
      "outputs": [],
      "source": [
        "bisenet_model = BiSeNetV2(n_classes=NUM_CLASSES,output_aux=True,pretrained=False) #meglio toglierla perchè genera bias\n",
        "bisenet_model.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85T4jE7qdS1a"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index=255,reduction='none') # da consegna ignore_index=255\n",
        "parameters_to_optimize = bisenet_model.parameters() \n",
        "optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_mIoU(y_true, y_pred,n_classes):\n",
        "     # ytrue, ypred is a flatten vector\n",
        "     y_pred = y_pred.cpu().flatten()\n",
        "     y_true = y_true.cpu().flatten()\n",
        "     current = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
        "     # compute mean iou\n",
        "     intersection = np.diag(current)\n",
        "     ground_truth_set = current.sum(axis=1)\n",
        "     predicted_set = current.sum(axis=0)\n",
        "     union = ground_truth_set + predicted_set - intersection\n",
        "     IoU = intersection / union.astype(np.float32)\n",
        "     return np.mean(IoU)  \n",
        "\n",
        "def compute_IoU(y_true, y_pred,n_classes):\n",
        "     # ytrue, ypred is a flatten vector\n",
        "     y_pred = y_pred.cpu().flatten()\n",
        "     y_true = y_true.cpu().flatten()\n",
        "     current = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
        "     # compute mean iou\n",
        "     intersection = np.diag(current)\n",
        "     ground_truth_set = current.sum(axis=1)\n",
        "     predicted_set = current.sum(axis=0)\n",
        "     union = ground_truth_set + predicted_set - intersection\n",
        "     IoU = intersection / union.astype(np.float32)\n",
        "     return IoU \n",
        "\n",
        "def plotLoss(train):\n",
        "  epochs = np.array([a for a in range(NUM_EPOCHS)]).reshape(NUM_EPOCHS,1)\n",
        "  plt.figure()\n",
        "  #plt.plot(epochs,val,label='val_loss')\n",
        "  plt.plot(epochs,train,label='train_loss')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "def plotmIoU(train):\n",
        "  epochs = np.array([a for a in range(NUM_EPOCHS)]).reshape(NUM_EPOCHS,1)\n",
        "  plt.figure()\n",
        "  #plt.plot(epochs,val,label='val_loss')\n",
        "  plt.plot(epochs,train,label='train_mIoU')\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "eFiWN6RO3jkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGjhngmUfK3t"
      },
      "outputs": [],
      "source": [
        "net = bisenet_model.half().to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "\n",
        "cudnn.benchmark # Calling this optimizes runtime\n",
        "\n",
        "#current_step = 0\n",
        "# Start iterating over the epochs\n",
        "#!nvidia-smi\n",
        "\n",
        "loss_for_epochs = []\n",
        "mIoU_for_epochs = []\n",
        "best_mIoU = 0\n",
        "file_path = \"./bisenet_best_mIoU_\"+ str(LR) + \"_tranformation\" + \".pt\"\n",
        "drive_path = \"/content/drive/MyDrive/best_modelB_mIoU\"+str(best_mIoU)+\".pt\"\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  print('Starting epoch {}/{}, LR = {}'.format(epoch+1, NUM_EPOCHS, scheduler.get_lr()))\n",
        "  current_step=0\n",
        "  # Iterate over the dataset\n",
        "  for images, labels in train_dataloader_A:\n",
        "    # Bring data over the device of choice\n",
        "    \n",
        "    images = images.half().to(DEVICE)\n",
        "    labels = labels.half().to(DEVICE)\n",
        "    #print(\"GPU Allocation after moving images and labels\")\n",
        "    #!nvidia-smi\n",
        "    net.train() # Sets module in training mode\n",
        "\n",
        "    # PyTorch, by default, accumulates gradients after each backward pass\n",
        "    # We need to manually set the gradients to zero before starting a new iteration\n",
        "    optimizer.zero_grad() # Zero-ing the gradients\n",
        "\n",
        "    # Forward pass to the network\n",
        "    output1,output2,output3,output4,output5 = net(images)\n",
        "    pred1 = output1.argmax(dim=1)\n",
        "    pred2 = output2.argmax(dim=1)\n",
        "    pred3 = output3.argmax(dim=1)\n",
        "    pred4 = output4.argmax(dim=1)\n",
        "    pred5 = output5.argmax(dim=1)\n",
        "    \n",
        "    # #print(f\"{pred1.size()}\")\n",
        "    # # print(type(images[0][0][0][0]))\n",
        "    # # print(\"pred_size=\"+str(pred1.size()))\n",
        "    # pred1_ = torch.flatten(pred1)\n",
        "    # pred2_ = torch.flatten(pred2)\n",
        "    # pred3_ = torch.flatten(pred3)\n",
        "    # pred4_ = torch.flatten(pred4)\n",
        "    # pred5_ = torch.flatten(pred5)\n",
        "\n",
        "\n",
        "    # labels_ = torch.flatten(labels)\n",
        "    loss1 = criterion(output1,labels.long())[labels!=255].mean()\n",
        "    loss2 = criterion(output2,labels.long())[labels!=255].mean()\n",
        "    loss3 = criterion(output3,labels.long())[labels!=255].mean()\n",
        "    loss4 = criterion(output4,labels.long())[labels!=255].mean()\n",
        "    loss5 = criterion(output5,labels.long())[labels!=255].mean()\n",
        "\n",
        "    loss = loss1+loss2+loss3+loss4+loss5\n",
        "    \n",
        "    # Compute loss based on output and ground truth\n",
        "    print(\"loss size:\",loss.size())\n",
        "    # Log loss\n",
        "    if current_step % LOG_FREQUENCY == 0:\n",
        "      print('Step {}, Loss {}'.format(current_step, loss.item()))\n",
        "      print('pred1->{} labels->{}'.format(pred1.size(),labels.size()))\n",
        "      #inserire unsqueeze alla posizione 1\n",
        "      #pred1 = torch.unsqueeze(pred1,1)\n",
        "      #labels = torch.unsqueeze(labels,1)\n",
        "      #print('pred1->{} labels->{}'.format(pred1.size(),labels.size()))\n",
        "      mIoU = compute_mIoU(labels,pred1,n_classes=19)\n",
        "      if best_mIoU < mIoU:\n",
        "        print(\"NEW BEST mIoU!\")\n",
        "        best_mIoU = mIoU\n",
        "        torch.save(bisenet_model.state_dict(), file_path)\n",
        "      print('Step {}, mIoU {}'.format(current_step, mIoU))\n",
        "\n",
        "    # Compute gradients for each layer and update weights\n",
        "    #loss1.requires_grad=True\n",
        "    #loss2.requires_grad=True\n",
        "    #loss3.requires_grad=True\n",
        "    #loss4.requires_grad=True\n",
        "    #loss5.requires_grad=True\n",
        "\n",
        "    #loss.requires_grad = True\n",
        "    loss.backward()\n",
        "    \n",
        "    #loss1.backward()  # backward pass: computes gradients\n",
        "    #loss2.backward()  # backward pass: computes gradients\n",
        "    #loss3.backward()  # backward pass: computes gradients\n",
        "    #loss4.backward()  # backward pass: computes gradients\n",
        "    #loss5.backward()  # backward pass: computes gradients\n",
        "\n",
        "    #torch.cuda.empty_cache()    \n",
        "\n",
        "  \n",
        "    optimizer.step() # update weights based on accumulated gradients\n",
        "\n",
        "    current_step += 1\n",
        "\n",
        "  loss_for_epochs.append(loss.item())\n",
        "  mIoU_for_epochs.append(mIoU)\n",
        "  # Step the scheduler\n",
        "  scheduler.step() \n",
        "\n",
        "plotLoss(loss_for_epochs)\n",
        "plotmIoU(mIoU_for_epochs)\n",
        "!cp file_path drive_path"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#torch.save(bisenet_model.state_dict(), \"/content/drive/MyDrive/Results/Step2/LR5e-1_10epochs_batchsize16/bisenet_best_mIoU3e-1_0.5_tranformation.pt\")\n",
        "#net = BiSeNetV2(n_classes=20)\n",
        "#net.load_state_dict(torch.load(\"/content/drive/MyDrive/Results/Step2/LR1e-0_10epochs_batchsize16/datasetB_mIoU_1.0_tranformation/bisenet_best_mIoU_1.0_tranformation (1).pt\"),strict=False)"
      ],
      "metadata": {
        "id": "QamfwuMM1GMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0hdP0HygyGk"
      },
      "outputs": [],
      "source": [
        "from torchvision import ops\n",
        "from tqdm import tqdm\n",
        "net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "net.train(False) # Set Network to evaluation mode\n",
        "net=net.half()\n",
        "running_corrects = 0\n",
        "torch.cuda.empty_cache() \n",
        "mIoU = 0\n",
        "count = 0\n",
        "for images, labels in tqdm(test_dataloader_A):\n",
        "  images = images.half().to(DEVICE)\n",
        "  labels = labels.half().to(DEVICE)\n",
        "  # print(images.size())\n",
        "  # print(labels.size())\n",
        "  # Forward Pass\n",
        "  outputs = net(images,test=True,use_test_resize=False)\n",
        "  preds = outputs.argmax(dim=1)\n",
        "  # print(outputs.size())\n",
        "  mIoU += compute_mIoU(labels,preds,NUM_CLASSES)\n",
        "  count += 1\n",
        "  \n",
        "  # iou = ops.box_iou(labels, outputs)\n",
        "\n",
        "  # print('IOU : ', iou.numpy()[0][0])\n",
        "print(\"mIoU = \",mIoU/count)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1FXNmzixwaov5rVFiZTCD4XneHxGZVaue",
      "authorship_tag": "ABX9TyM1Is0w5TGJY6C/OMXoL2lg",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
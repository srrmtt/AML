{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Kk0rtAlnSlDF",
        "jiwWzjzSio-h",
        "g1GznJhObXPk",
        "Sy4KrHClbAmC",
        "UPwkOR8taVdN",
        "Ru8vllrMbgvL",
        "z0MWgLingzhw",
        "lrLs_T2Qd0kc",
        "Gr9BxL8zeBfv"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srrmtt/AML/blob/main/RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qf3z5SqWZ91b"
      },
      "source": [
        "# Torch "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbtEmI1AiTkF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "140bbbc7-8647-43e8-b014-d608b8bf12fc"
      },
      "source": [
        "!pip3 install 'torch==1.3.1'\n",
        "!pip3 install 'torchvision==0.5.0'\n",
        "!pip3 install 'Pillow-SIMD'\n",
        "!pip3 install 'tqdm'\n",
        "!pip3 install \"colorama\"\n",
        "\n",
        "import torch\n",
        "#use GPU if available \n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") #'cpu' # 'cuda' or 'cpu'\n",
        "print(DEVICE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch==1.3.1\n",
            "  Downloading torch-1.3.1-cp37-cp37m-manylinux1_x86_64.whl (734.6 MB)\n",
            "\u001b[K     |██████▊                         | 153.3 MB 1.4 MB/s eta 0:07:02"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czjvnq3FjBmh"
      },
      "source": [
        "# Download Dataset GTEA61"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGOhXMNqjMed"
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "#drive.mount('/content/drive')\n",
        "import sys, os\n",
        "           \n",
        "#1YKfdhB9Xxh4pmND1V3gcm3Gyjc8v8idq\n",
        "if not os.path.isfile('/content/GTEA61.zip'):\n",
        "  !gdown --id 1Z5RWA8yKIy0PvxMlScV-aAz22ITtivfk # 3-5 min\n",
        "  !jar xvf  \"/content/GTEA61.zip\"\n",
        "\n",
        "if not os.path.isdir('/content/GTEA61'):\n",
        "  print(\"Dataset doesn't exist\")\n",
        "\n",
        "#Weights\n",
        "if not os.path.isfile(\"/content/best_model_state_dict_rgb_split2.pth\"):\n",
        "  !gdown --id 1B7Xh6hQ9Py8fmL-pjmLzlCent6dnuex5 # 3-5 min\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kk0rtAlnSlDF"
      },
      "source": [
        "\n",
        "# Download Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8xcWfReaSd_"
      },
      "source": [
        "!git clone \"https://github.com/plana93/Homework_AIML.git\" \n",
        "#!rm -r \"/content/Homework_AIML\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiwWzjzSio-h"
      },
      "source": [
        "\n",
        "\n",
        "# Import Code\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wl6fSd3MXofW"
      },
      "source": [
        "import os\n",
        "import logging\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.backends import cudnn\n",
        "import torchvision\n",
        "from colorama import init\n",
        "from colorama import Fore, Back, Style\n",
        "\n",
        "from torchvision.models import resnet34\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"/content/Homework_AIML/\")\n",
        "import Homework_AIML\n",
        "from Homework_AIML import *\n",
        "\n",
        "from gtea_dataset import GTEA61, GTEA61_flow, GTEA61_2Stream\n",
        "from spatial_transforms import (Compose, ToTensor, CenterCrop, Scale, Normalize, MultiScaleCornerCrop,\n",
        "                                RandomHorizontalFlip)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1GznJhObXPk"
      },
      "source": [
        "#**Learning without Temporal information** (avgpool)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sy4KrHClbAmC"
      },
      "source": [
        "#MAIN PARAMs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-tz9mHPbCYW",
        "outputId": "5a911630-35ef-41a1-8d9d-d7600842d60d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        }
      },
      "source": [
        "homework_step = 0 #--> Learning without Temporal information (avgpool)\n",
        "#homework_step = 1 #--> Learning with Temporal information (LSTM)\n",
        "#homework_step = 2 #--> Learning with Spatio-Temporal information (ConvLSTM)\n",
        "\n",
        "\n",
        "\n",
        "DATA_DIR = '/content/GTEA61/' #path dataset\n",
        "model_folder = '/content/saved_models/' + \"/\" + \"homework_step\"+ str(homework_step) + \"/\" #path to save model \n",
        "if not os.path.isdir(model_folder):\n",
        "    os.makedirs(model_folder)\n",
        "\n",
        "\n",
        "# All this param can be change!\n",
        "\n",
        "NUM_CLASSES = 61     \n",
        "BATCH_SIZE = 64 \n",
        "LR = 0.001            # The initial Learning Rate\n",
        "MOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
        "WEIGHT_DECAY = 4e-5  # Regularization, you can keep this at the default\n",
        "NUM_EPOCHS = 200     # Total number of training epochs (iterations over dataset)\n",
        "STEP_SIZE = [25, 75, 150] # How many epochs before decreasing learning rate (if using a step-down policy)\n",
        "GAMMA = 0.1          # Multiplicative factor for learning rate step-down\n",
        "MEM_SIZE = 512       # Dim of internal state of LSTM or ConvLSTM\n",
        "SEQ_LEN = 3          # Num Frames\n",
        "\n",
        "# this dictionary is needed for the logger class\n",
        "parameters = {'DEVICE':DEVICE, 'NUM_CLASSES':NUM_CLASSES, 'BATCH_SIZE':BATCH_SIZE,\n",
        "             'LR':LR, 'MOMENTUM':MOMENTUM, 'WEIGHT_DECAY':WEIGHT_DECAY, 'NUM_EPOCHS':NUM_EPOCHS,\n",
        "             'STEP_SIZE':STEP_SIZE, 'GAMMA':GAMMA, 'MEM_SIZE':MEM_SIZE, 'SEQ_LEN':SEQ_LEN}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-405fb615342e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mDATA_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/GTEA61/'\u001b[0m \u001b[0;31m#path dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/saved_models/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"homework_step\"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhomework_step\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m \u001b[0;31m#path to save model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPwkOR8taVdN"
      },
      "source": [
        "#Dataloaders & Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmxnQXSYaeWv"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LT_Gy79SgBLq"
      },
      "source": [
        "# Normalize\n",
        "normalize = Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "spatial_transform = Compose([Scale(256), RandomHorizontalFlip(), MultiScaleCornerCrop([1, 0.875, 0.75, 0.65625], 224),\n",
        "                             ToTensor(), normalize])\n",
        "spatial_transform_val = Compose([Scale(256), CenterCrop(224), ToTensor(), normalize])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T69vfGGhjKa_",
        "outputId": "66aadc83-8ec4-4f9b-e882-e4c3af32af50"
      },
      "source": [
        "# Prepare Pytorch train/test Datasets\n",
        "train_dataset = GTEA61(DATA_DIR, split='train', transform=spatial_transform, seq_len=SEQ_LEN)\n",
        "test_dataset = GTEA61(DATA_DIR, split='test', transform=spatial_transform_val, seq_len=SEQ_LEN)\n",
        "\n",
        "# Check dataset sizes\n",
        "print('Train Dataset: {}'.format(len(train_dataset)))\n",
        "print('Test Dataset: {}'.format(len(test_dataset)))\n",
        "\n",
        "# Dataloaders iterate over pytorch datasets and transparently provide useful functions (e.g. parallelization and shuffling)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)\n",
        "val_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['S1', 'S2', 'S3', 'S4']\n",
            "['S1', 'S2', 'S3', 'S4']\n",
            "Train Dataset: 341\n",
            "Test Dataset: 116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21wjiwvW-OPQ"
      },
      "source": [
        "#Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMWuE-4SHxoY"
      },
      "source": [
        "import torch\n",
        "import resnetMod\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "\n",
        "# LSTM\n",
        "class MyLSTMCell(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(MyLSTMCell, self).__init__()\n",
        "        \n",
        "\n",
        "    def forward(self, x, state):\n",
        "        if state is None:\n",
        "            state = (Variable(torch.randn(x.size(0), x.size(1)).cuda()),\n",
        "                     Variable(torch.randn(x.size(0), x.size(1)).cuda()))\n",
        "        \n",
        "        ################################## \n",
        "        # You should implement this part #\n",
        "        ##################################\n",
        "\n",
        "        return  None, None\n",
        "\n",
        "\n",
        "#ConvLSTM\n",
        "class MyConvLSTMCell(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, kernel_size=3, stride=1, padding=1):\n",
        "        super(MyConvLSTMCell, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.conv_i_xx = nn.Conv2d(input_size, hidden_size, kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "        self.conv_i_hh = nn.Conv2d(hidden_size, hidden_size, kernel_size=kernel_size, stride=stride, padding=padding,\n",
        "                                   bias=False)\n",
        "\n",
        "        self.conv_f_xx = nn.Conv2d(input_size, hidden_size, kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "        self.conv_f_hh = nn.Conv2d(hidden_size, hidden_size, kernel_size=kernel_size, stride=stride, padding=padding,\n",
        "                                   bias=False)\n",
        "\n",
        "        self.conv_c_xx = nn.Conv2d(input_size, hidden_size, kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "        self.conv_c_hh = nn.Conv2d(hidden_size, hidden_size, kernel_size=kernel_size, stride=stride, padding=padding,\n",
        "                                   bias=False)\n",
        "\n",
        "        self.conv_o_xx = nn.Conv2d(input_size, hidden_size, kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "        self.conv_o_hh = nn.Conv2d(hidden_size, hidden_size, kernel_size=kernel_size, stride=stride, padding=padding,\n",
        "                                   bias=False)\n",
        "\n",
        "        torch.nn.init.xavier_normal_(self.conv_i_xx.weight)\n",
        "        torch.nn.init.constant_(self.conv_i_xx.bias, 0)\n",
        "        torch.nn.init.xavier_normal_(self.conv_i_hh.weight)\n",
        "\n",
        "        torch.nn.init.xavier_normal_(self.conv_f_xx.weight)\n",
        "        torch.nn.init.constant_(self.conv_f_xx.bias, 0)\n",
        "        torch.nn.init.xavier_normal_(self.conv_f_hh.weight)\n",
        "\n",
        "        torch.nn.init.xavier_normal_(self.conv_c_xx.weight)\n",
        "        torch.nn.init.constant_(self.conv_c_xx.bias, 0)\n",
        "        torch.nn.init.xavier_normal_(self.conv_c_hh.weight)\n",
        "\n",
        "        torch.nn.init.xavier_normal_(self.conv_o_xx.weight)\n",
        "        torch.nn.init.constant_(self.conv_o_xx.bias, 0)\n",
        "        torch.nn.init.xavier_normal_(self.conv_o_hh.weight)\n",
        "\n",
        "    def forward(self, x, state):\n",
        "        if state is None:\n",
        "            state = (Variable(torch.randn(x.size(0), x.size(1), x.size(2), x.size(3)).cuda()),\n",
        "                     Variable(torch.randn(x.size(0), x.size(1), x.size(2), x.size(3)).cuda()))\n",
        "        \n",
        "        ################################## \n",
        "        # You should implement this part #\n",
        "        ##################################\n",
        "\n",
        "        return  None, None\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Network \n",
        "class ourModel(nn.Module):\n",
        "    def __init__(self, num_classes=61, mem_size=512, homework_step = 0 , DEVICE=\"\"):\n",
        "        super(ourModel, self).__init__()\n",
        "        self.DEVICE = DEVICE\n",
        "        self.num_classes = num_classes\n",
        "        self.resNet = resnetMod.resnet34(True, True)\n",
        "        self.mem_size = mem_size\n",
        "        self.weight_softmax = self.resNet.fc.weight\n",
        "        self.homework_step = homework_step\n",
        "        if self.homework_step == 1:\n",
        "          self.lstm_cell = MyLSTMCell(512, mem_size)\n",
        "        elif self.homework_step == 2:\n",
        "          self.lstm_cell = MyConvLSTMCell(512, mem_size)\n",
        "\n",
        "        self.avgpool = nn.AvgPool2d(7)\n",
        "        self.dropout = nn.Dropout(0.7)\n",
        "        self.fc = nn.Linear(mem_size, self.num_classes)\n",
        "        self.classifier = nn.Sequential(self.dropout, self.fc)\n",
        "\n",
        "    def forward(self, inputVariable):\n",
        "        #Learning without Temporal information (mean)\n",
        "        if self.homework_step == 0:\n",
        "            video_level_features = torch.zeros((inputVariable.size(1), self.mem_size)).to(self.DEVICE)\n",
        "            for t in range(inputVariable.size(0)):\n",
        "                #spatial_frame_feat: (bs, 512, 7, 7)\n",
        "                _, spatial_frame_feat, _ = self.resNet(inputVariable[t])\n",
        "                #frames_feat: (bs, 512)\n",
        "                frame_feat = self.avgpool(spatial_frame_feat).view(spatial_frame_feat.size(0), -1)\n",
        "                video_level_features = video_level_features + frame_feat\n",
        "\n",
        "            video_level_features = video_level_features / inputVariable.size(0)\n",
        "            logits = self.classifier(video_level_features)\n",
        "            return logits, video_level_features\n",
        "\n",
        "        #Learning with Temporal information (LSTM)\n",
        "        elif self.homework_step == 1:\n",
        "            state = ( torch.zeros((inputVariable.size(1), self.mem_size)).to(self.DEVICE),\n",
        "                     torch.zeros((inputVariable.size(1), self.mem_size)).to(self.DEVICE) ) \n",
        "            for t in range(inputVariable.size(0)):\n",
        "                #spatial_frame_feat: (bs, 512, 7, 7)\n",
        "                _, spatial_frame_feat, _ = self.resNet(inputVariable[t])\n",
        "                #frames_feat: (bs, 512)\n",
        "                frame_feat = self.avgpool(spatial_frame_feat).view(state[1].size(0), -1)\n",
        "                state = self.lstm_cell(frame_feat, state)\n",
        "\n",
        "            video_level_features = state[1]\n",
        "            logits = self.classifier(video_level_features)\n",
        "            return logits, video_level_features\n",
        "\n",
        "        #Learning with Temporal information (ConvLSTM)\n",
        "        elif self.homework_step == 2:\n",
        "            state = (torch.zeros((inputVariable.size(1), self.mem_size, 7, 7)).to(self.DEVICE),\n",
        "                     torch.zeros((inputVariable.size(1), self.mem_size, 7, 7)).to(self.DEVICE))\n",
        "            for t in range(inputVariable.size(0)):\n",
        "                #spatial_frame_feat: (bs, 512, 7, 7)\n",
        "                _, spatial_frame_feat, _ = self.resNet(inputVariable[t])\n",
        "                state = self.lstm_cell(spatial_frame_feat, state)\n",
        "            video_level_features = self.avgpool(state[1]).view(state[1].size(0), -1)\n",
        "            logits = self.classifier(video_level_features)\n",
        "            return logits, video_level_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ru8vllrMbgvL"
      },
      "source": [
        "#Build Model - Loss - Opt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZe-ZbEL7z3x"
      },
      "source": [
        "#CUDA_LAUNCH_BLOCKING=1\n",
        "validate = True\n",
        "\n",
        "model = ourModel(num_classes=NUM_CLASSES, mem_size=MEM_SIZE, homework_step=homework_step, DEVICE=DEVICE) #model\n",
        "\n",
        "#Train only the lstm cell and classifier\n",
        "model.train(False)\n",
        "for params in model.parameters():\n",
        "    params.requires_grad = False\n",
        "\n",
        "if homework_step > 0:\n",
        "    for params in model.lstm_cell.parameters():\n",
        "        params.requires_grad = True\n",
        "    model.lstm_cell.train(True)\n",
        "\n",
        "for params in model.classifier.parameters():\n",
        "    params.requires_grad = True\n",
        "model.classifier.train(True)\n",
        "\n",
        "\n",
        "model = model.to(DEVICE)\n",
        "\n",
        "#model.load_state_dict(torch.load(\"/content/best_model_state_dict_rgb_split2.pth\", map_location=torch.device('cpu')), strict=True)\n",
        "\n",
        "\n",
        "#Loss\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "#Opt\n",
        "trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer_fn = optim.Adam(trainable_params, lr=LR, weight_decay=WEIGHT_DECAY, eps=1e-4)\n",
        "#Scheduler\n",
        "optim_scheduler = optim.lr_scheduler.MultiStepLR(optimizer_fn, milestones=STEP_SIZE, gamma=GAMMA)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0MWgLingzhw"
      },
      "source": [
        "#Training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-uE2A9eHmtn"
      },
      "source": [
        "train_iter = 0\n",
        "val_iter = 0\n",
        "min_accuracy = 0\n",
        "\n",
        "trainSamples = len(train_dataset) - (len(train_dataset) % BATCH_SIZE)\n",
        "val_samples = len(test_dataset) \n",
        "iterPerEpoch = len(train_loader)\n",
        "val_steps = len(val_loader)\n",
        "cudnn.benchmark\n",
        "model_checkpoint = \"model\" #name\n",
        "\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    epoch_loss = 0\n",
        "    numCorrTrain = 0\n",
        "    \n",
        "    #blocks to train\n",
        "    if homework_step > 0:\n",
        "        model.lstm_cell.train(True)\n",
        "    model.classifier.train(True)\n",
        "    \n",
        "    \n",
        "    for i, (inputs, targets) in enumerate(train_loader):\n",
        "        train_iter += 1\n",
        "        optimizer_fn.zero_grad()\n",
        "        \n",
        "        # (BS, Frames, C, W, H) --> (Frames, BS, C, W, H)\n",
        "        inputVariable = inputs.permute(1, 0, 2, 3, 4).to(DEVICE)\n",
        "        labelVariable = targets.to(DEVICE)\n",
        "\n",
        "        # feeds in model\n",
        "        output_label, _ = model(inputVariable)\n",
        "        \n",
        "        # compute loss \n",
        "        loss = loss_fn(output_label, labelVariable)\n",
        "\n",
        "        # backward loss and optimizer step \n",
        "        loss.backward()\n",
        "        optimizer_fn.step()\n",
        "        \n",
        "        #compute the training accuracy \n",
        "        _, predicted = torch.max(output_label.data, 1)\n",
        "        numCorrTrain += torch.sum(predicted == labelVariable.data).data.item()\n",
        "        step_loss = loss.data.item()\n",
        "        epoch_loss += step_loss\n",
        "    \n",
        "    avg_loss = epoch_loss/iterPerEpoch\n",
        "    trainAccuracy = (numCorrTrain / trainSamples) * 100\n",
        "    #train_logger.add_epoch_data(epoch+1, trainAccuracy, avg_loss)\n",
        "    print(Fore.BLACK + 'Train: Epoch = {} | Loss = {:.3f} | Accuracy = {:.3f}'.format(epoch+1, avg_loss, trainAccuracy))\n",
        "    if validate:\n",
        "        if (epoch+1) % 1 == 0:\n",
        "            model.train(False)\n",
        "            val_loss_epoch = 0\n",
        "            numCorr = 0\n",
        "            for j, (inputs, targets) in enumerate(val_loader):\n",
        "                val_iter += 1\n",
        "                inputVariable = inputs.permute(1, 0, 2, 3, 4).to(DEVICE)\n",
        "                labelVariable = targets.to(DEVICE)\n",
        "                \n",
        "                output_label, _ = model(inputVariable)\n",
        "                val_loss = loss_fn(output_label, labelVariable)\n",
        "                val_loss_step = val_loss.data.item()\n",
        "                val_loss_epoch += val_loss_step\n",
        "                _, predicted = torch.max(output_label.data, 1)\n",
        "                numCorr += torch.sum(predicted == labelVariable.data).data.item()\n",
        "                #val_logger.add_step_data(val_iter, numCorr, val_loss_step)\n",
        "                \n",
        "            val_accuracy = (numCorr / val_samples) * 100\n",
        "            avg_val_loss = val_loss_epoch / val_steps\n",
        "\n",
        "            print(Fore.GREEN + 'Val: Epoch = {} | Loss {:.3f} | Accuracy = {:.3f}'.format(epoch + 1, avg_val_loss, val_accuracy))\n",
        "            if val_accuracy > min_accuracy:\n",
        "                print(\"[||| NEW BEST on val||||]\")\n",
        "                save_path_model = os.path.join(model_folder, model_checkpoint)\n",
        "                torch.save(model.state_dict(), save_path_model)\n",
        "                min_accuracy = val_accuracy\n",
        "    \n",
        "    optim_scheduler.step()\n",
        "\n",
        "print(Fore.CYAN + \"Best Acc --> \", min_accuracy)\n",
        "print(Fore.CYAN + \"Last Acc --> \", val_accuracy)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrLs_T2Qd0kc"
      },
      "source": [
        "#Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqK1ExB0cl8D"
      },
      "source": [
        "model.train(False)\n",
        "val_loss_epoch = 0\n",
        "numCorr = 0\n",
        "val_iter = 0\n",
        "val_samples = len(test_dataset) \n",
        "val_steps = len(val_loader)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for j, (inputs, targets) in enumerate(val_loader):\n",
        "        val_iter += 1\n",
        "        inputVariable = inputs.permute(1, 0, 2, 3, 4).to(DEVICE)\n",
        "        labelVariable = targets.to(DEVICE)\n",
        "        \n",
        "        output_label, _ = model(inputVariable)\n",
        "        val_loss = loss_fn(output_label, labelVariable)\n",
        "        val_loss_step = val_loss.data.item()\n",
        "        val_loss_epoch += val_loss_step\n",
        "        _, predicted = torch.max(output_label.data, 1)\n",
        "        numCorr += torch.sum(predicted == labelVariable.data).data.item()\n",
        "        \n",
        "    val_accuracy = (numCorr / val_samples) * 100\n",
        "    avg_val_loss = val_loss_epoch / val_steps\n",
        "\n",
        "print('Loss {:.3f} | Accuracy = {:.3f}'.format(avg_val_loss, val_accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gr9BxL8zeBfv"
      },
      "source": [
        "#**Learning with Temporal information** (LSTM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-qHYgnyf_wn"
      },
      "source": [
        "#**Learning with Spatio-Temporal information** (ConvLSTM)\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}